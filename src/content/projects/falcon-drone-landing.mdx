---
title: "FALCON — Dynamic Drone Landing Simulator"
subtitle: "AprilTags + sensor fusion + PID control, packaged as a modular library with a Python GUI."
date: "May 2025 – Jul 2025"
tags: ["Computer Vision", "Sensor Fusion", "PID", "Python"]
thumbnail: "/assets/falcon/Falcon GUI.png"
repo:
  url: "https://github.com/Kurokishi592/Falcon"
  label: "Kurokishi592/Falcon"
documents:
  - title: "Project Poster.pdf"
    url: "/assets/falcon/Project Poster.pdf"
    subtitle: "Final Project Poster"
  - title: "Project Report"
    url: "/assets/falcon/report.pdf"
    subtitle: "Detailed Project Report"
  - title: "certificate.pdf"
    url: "/assets/falcon/certificate.pdf"
    subtitle: "NUS Orbital Apollo 11 Certificate"
featured: false
---

>[!danger] This write up is still work-in-progress! Why not watch visit my Github for the user guide, read the poster and the project report (under Documents on this page) in the meantime? 
> If you have any questions, feel free to reach out to me!

## Overview

FALCON is a vision-based dynamic drone landing system that allows Unmanned Aerial Vehicles (UAVs) to land autonomously on moving platforms. It presents users with a Python-based GUI that abstracts backend algorithms for users to adapt FALCON’s capabilities into any drone, fine tune parameters and simulate in real time. At its core, FALCON uses AprilTags for real-time visual localization, sensor fusion for motion estimation, and a Proportional-Integral-Derivative (PID) controller with noise filtering for precise trajectory correction. As a modular and reusable software library, FALCON aims to be easily extensible for all users with various hardware and thus benefit the open-source robotics ecosystem.

This project achieved the Apollo 11 (Advanced) level under the NUS Orbital (CP2106: Independent Software Development Project), which is the School of Computing’s 1st year summer self-directed, independent work course.. This course exposes students to pick up software development skills on their own, and complete a small scale software project of their choice in an iterative software development life cycle. This is on top of the robotics-related skills applied to enhance this project's capabilities.

## Highlights

- AprilTag detection for relative pose.
- Sensor fusion and control loop tuning.
- GUI tooling for reproducible testing.

# My thoughts
This project idea was inspired by one of RobotX 2024's tasks that required an Unmanned Aerial Vehicle (UAV) to land autonomously on an Autonomous Surface Vessel (ASV).

Building up perception for autonomous manoeuvring fascinates me. This was how I leverage this academic platform to explore visual fudicials, localisation and controls. 

>[!note] TODO: complete this write up
>- What I learnt from AprilTag algorithm (v1 to v3 papers - recursive tag, optimisations, union find, etc)
>- QGC, Pixhawk -> MiniAUV Project
>- Simple UIUX
